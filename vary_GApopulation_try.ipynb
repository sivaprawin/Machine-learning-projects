{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sivaprawin/Machine-learning-projects/blob/main/vary_GApopulation_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuNXa8CZVQnH",
        "outputId": "6c4dcbf7-3d70-4448-f3fd-5d062d9cd55a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2LmlAzrSi0R",
        "outputId": "9cc4cf70-87d7-4d36-9314-c453d1b4c542"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 594 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Import necessary libraries and mount Google Drive (if using Colab)\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50, VGG19, InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess_input\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input as vgg_preprocess_input\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess_input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the path to your mounted drive containing \"healthy\" and \"patient\" folders\n",
        "data_dir = '/content/drive/MyDrive/dataset2'\n",
        "\n",
        "# Define a directory to save the preprocessed images in Colab's file system\n",
        "preprocessed_images_dir = '/content/preprocessed_images'\n",
        "os.makedirs(preprocessed_images_dir, exist_ok=True)\n",
        "\n",
        "# Create an ImageDataGenerator for data preprocessing\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 256,  # Scale pixel values to be in the range [0, 1]\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Generate and save batches of preprocessed images\n",
        "batch_size = 32\n",
        "target_size = (256, 256)  # Resize images to 256x256 pixels\n",
        "\n",
        "generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',  # Use 'categorical' for multi-class classification\n",
        "    save_to_dir=preprocessed_images_dir,  # Specify the directory to save the preprocessed images\n",
        "    save_prefix='preprocessed_',  # Prefix for saved image filenames\n",
        "    save_format='jpeg'  # Format for saved images\n",
        ")\n",
        "\n",
        "# Generate and save the preprocessed images\n",
        "for _ in range(len(generator)):\n",
        "    next(generator)\n",
        "\n",
        "# Define paths to your image folders\n",
        "healthy_dir = '/content/drive/MyDrive/dataset2/healthy'\n",
        "patient_dir = '/content/drive/MyDrive/dataset2/patient'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkMiJNqKUVxd"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Initialize lists to store features and labels\n",
        "all_features = []\n",
        "labels = []\n",
        "\n",
        "# Load pre-trained models\n",
        "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "vgg_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Define a function to extract features using a given model and preprocess input\n",
        "def extract_features(model, preprocess_input, img_path):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    features = model.predict(img_array)\n",
        "    return features.flatten()  # Flatten the features\n",
        "\n",
        "# Load, preprocess, and extract features from healthy images\n",
        "for filename in os.listdir(healthy_dir):\n",
        "    img_path = os.path.join(healthy_dir, filename)\n",
        "    resnet_features = extract_features(resnet_model, resnet_preprocess_input, img_path)\n",
        "    vgg_features = extract_features(vgg_model, vgg_preprocess_input, img_path)\n",
        "    inception_features = extract_features(inception_model, inception_preprocess_input, img_path)\n",
        "    combined_features = np.concatenate((resnet_features, vgg_features, inception_features))\n",
        "    all_features.append(combined_features)\n",
        "    labels.append(0)  # Label 0 for healthy\n",
        "\n",
        "# Load, preprocess, and extract features from patient images\n",
        "for filename in os.listdir(patient_dir):\n",
        "    img_path = os.path.join(patient_dir, filename)\n",
        "    resnet_features = extract_features(resnet_model, resnet_preprocess_input, img_path)\n",
        "    vgg_features = extract_features(vgg_model, vgg_preprocess_input, img_path)\n",
        "    inception_features = extract_features(inception_model, inception_preprocess_input, img_path)\n",
        "    combined_features = np.concatenate((resnet_features, vgg_features, inception_features))\n",
        "    all_features.append(combined_features)\n",
        "    labels.append(1)  # Label 1 for patient\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X = np.array(all_features)\n",
        "y = np.array(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzTeEwRgTtgB",
        "outputId": "e7f37582-a3b8-4d59-cb17-0fddc04f9b14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8212290502793296"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train,y_train)\n",
        "accuracy = knn.score(X_test, y_test)\n",
        "accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "k4wEV4dBUZLz",
        "outputId": "82da7c62-c651-4672-9e37-f4dee39f39f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The best population size is 45, and the peak accuracy is 89.39%\n",
            "The algorithm is frozen at population size 45 for future analyses.\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Define GA parameters\n",
        "# Define GA parameters\n",
        "population_size = 20  # Set your desired population size\n",
        "selection_candidates = min(10, population_size)  # Adjust this value as needed\n",
        "population_sizes = list(range(10, 51, 5))  # Vary population size from 10 to 50 with an increment of 5\n",
        "total_iterations = 200\n",
        "crossover_rate = 0.7\n",
        "mutation_rate = 0.3\n",
        "selection_candidates = 20\n",
        "random_seed = 13\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# Define a function to calculate fitness\n",
        "def calculate_fitness(candidate):\n",
        "    selected_train_features = X_train[:, candidate == 1]\n",
        "    selected_test_features = X_test[:, candidate == 1]\n",
        "    knn = KNeighborsClassifier(n_neighbors=3)\n",
        "    knn.fit(selected_train_features, y_train)\n",
        "    accuracy = knn.score(selected_test_features, y_test)\n",
        "    return accuracy\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7FISCDi_SNr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "052c7306-158d-4c8c-8a0f-4d5befc1c4ba"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8af0eaa5d33e>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Iterate through different population sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpopulation_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation_sizes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Reinitialize the population with binary vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0minitial_population\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'population_sizes' is not defined"
          ]
        }
      ],
      "source": [
        "# Initialize lists to record peak accuracies for each population size\n",
        "peak_accuracies = []\n",
        "\n",
        "# Iterate through different population sizes\n",
        "for population_size in population_sizes:\n",
        "    # Reinitialize the population with binary vectors\n",
        "    initial_population = np.random.randint(2, size=(population_size, X.shape[1]))\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    # Main GA loop\n",
        "# Main GA loop\n",
        "for iteration in range(total_iterations):\n",
        "    fitness_scores = []\n",
        "\n",
        "    # Calculate fitness for each candidate in the population\n",
        "    for candidate in initial_population:\n",
        "        fitness = calculate_fitness(candidate)\n",
        "        fitness_scores.append(fitness)\n",
        "\n",
        "    # Select the top candidates with the best accuracies\n",
        "    selected_indices = np.argsort(fitness_scores)[-population_size // 2:]\n",
        "    selected_population = initial_population[selected_indices]\n",
        "\n",
        "    # Perform crossover to create new candidates\n",
        "    crossover_population = []\n",
        "    for i in range(population_size // 2):\n",
        "        parent1 = selected_population[np.random.randint(population_size // 2)]\n",
        "        parent2 = selected_population[np.random.randint(population_size // 2)]\n",
        "        crossover_point = np.random.randint(0, len(parent1))\n",
        "        offspring1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n",
        "        offspring2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))\n",
        "        crossover_population.append(offspring1)\n",
        "        crossover_population.append(offspring2)\n",
        "\n",
        "    # Perform mutation\n",
        "    for i in range(population_size):\n",
        "        for j in range(len(crossover_population[i])):\n",
        "            if np.random.rand() < mutation_rate:\n",
        "                crossover_population[i][j] = 1 - crossover_population[i][j]  # Flip the bit\n",
        "\n",
        "    # Update the population for the next iteration\n",
        "    initial_population = np.array(crossover_population)\n",
        "\n",
        "    # Calculate the fitness of the best candidate\n",
        "    best_fitness = max(fitness_scores)\n",
        "\n",
        "    # Check if the current iteration achieved a new peak accuracy\n",
        "    if best_fitness > best_accuracy:\n",
        "        best_accuracy = best_fitness\n",
        "\n",
        "    # Record the peak accuracy for this population size\n",
        "    peak_accuracies.append(best_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXocwIYs_XSJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "250047c8-24d3-430b-d5f4-46df5d83475c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-801958eec12c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Find the population size with the highest peak accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_population_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpopulation_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeak_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Freeze the algorithm at the best population size for future analyses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfinal_population_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_population_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'population_sizes' is not defined"
          ]
        }
      ],
      "source": [
        "# Find the population size with the highest peak accuracy\n",
        "best_population_size = population_sizes[np.argmax(peak_accuracies)]\n",
        "\n",
        "# Freeze the algorithm at the best population size for future analyses\n",
        "final_population_size = best_population_size\n",
        "\n",
        "print(f\"The best population size is {best_population_size}, and the peak accuracy is {max(peak_accuracies)*100:.2f}%\")\n",
        "print(f\"The algorithm is frozen at population size {final_population_size} for future analyses.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMU6sfpfUbh6"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Assuming you have the best binary vector as 'best_vector' from the GA\n",
        "\n",
        "# Select relevant features based on the best binary vector\n",
        "selected_train_features = X_train[:, best_vector == 1]\n",
        "selected_test_features = X_test[:, best_vector == 1]\n",
        "\n",
        "# Train a KNN classifier on the selected training features\n",
        "knn = KNeighborsClassifier(n_neighbors=3)  # You can adjust the number of neighbors\n",
        "knn.fit(selected_train_features, y_train)\n",
        "\n",
        "# Evaluate the KNN classifier on the selected testing features\n",
        "accuracy = knn.score(selected_test_features, y_test)\n",
        "\n",
        "print(f\"Accuracy using the optimized feature set: {accuracy*100:.2f}%\")\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "y_pred = knn.predict(selected_test_features)\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Display the confusion matrix using a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            xticklabels=[\"Healthy\", \"Patient\"], yticklabels=[\"Healthy\", \"Patient\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Calculate the number of correct and incorrect predictions\n",
        "correct_predictions = np.diag(confusion).sum()\n",
        "incorrect_predictions = confusion.sum() - correct_predictions\n",
        "\n",
        "# Print the results\n",
        "print(f\"Total values successfully predicted: {correct_predictions} ({confusion[0, 0] + confusion[1, 1]})\")\n",
        "print(f\"Incorrect predictions: {incorrect_predictions} ({confusion[0, 1] + confusion[1, 0]})\")\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjdifs2Uh9Ytz842eIPZ5A",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}